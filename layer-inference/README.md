# Inference Layer

Mission: model backends and runtime model serving. This layer is never called
directly by clients; all requests come through LiteLLM.

See root docs: `/home/christopherbailey/homelab-llm/SYSTEM_OVERVIEW.md`.
Use `docs/` for deeper inference notes.
