# OptiLLM Local env (Orin)
OPTILLM_API_KEY=change-me
OPTILLM_MODEL=meta-llama/Llama-3.1-8B-Instruct

# Caches (recommended)
HF_HOME=/opt/homelab/.cache/huggingface
TRANSFORMERS_CACHE=/opt/homelab/.cache/huggingface
TORCH_HOME=/opt/homelab/.cache/torch

# Optional
CUDA_VISIBLE_DEVICES=0
